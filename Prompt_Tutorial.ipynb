{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d24652-75aa-40b2-bbcb-cbb2e8f41c10",
   "metadata": {},
   "source": [
    "llama 3.1 call setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50225cc3-83d3-4259-8eb3-f2c88d16f0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def send_prompt(messages: []):\n",
    "    return ollama.chat(\n",
    "        model=\"llama3.1\",\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "def create_prompt(prompt: str):\n",
    "    return [{\"role\": \"user\", \"content\": prompt}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156f7c07-d923-41e6-84e3-805829638fbf",
   "metadata": {},
   "source": [
    "Zero-Shot Learning: This involves giving the AI a task without any prior examples. You describe what you want in detail, assuming the AI has no prior knowledge of the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4e5c0e-f18c-412e-9905-0229c962bee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-Shot\n",
    "zero_shot = \"\"\"\n",
    "    Explain what a large language model is.\"\"\"\n",
    "\n",
    "prompt = create_prompt(zero_shot)\n",
    "\n",
    "print(send_prompt(zero_shot)[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8fea36-7c6b-4158-932a-75297aa72d70",
   "metadata": {},
   "source": [
    "One-Shot Learning: You provide one example along with your prompt. This helps the AI understand the context or format you’re expecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc8ccf-cc18-4d97-af11-d266fc893457",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot = \"\"\"\n",
    "    A Foundation Model in AI refers to a model like GPT-3,\n",
    "    which is trained on a large dataset and can be adapted to various tasks.\n",
    "    Explain what BERT is in this context.\"\"\"\n",
    "\n",
    "prompt = create_prompt(one_shot)\n",
    "\n",
    "print(send_prompt(prompt)[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e371dde-0e1d-4b97-85ba-b39a6d3486da",
   "metadata": {},
   "source": [
    "Few-Shot Learning: This involves providing a few examples (usually 2–5) to help the AI understand the pattern or style of the response you’re looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b26ce1-5e8f-4cc6-b460-573414b35227",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot = \"\"\"\n",
    "    Foundation Models such as GPT-3 are used for natural language\n",
    "    processing, while models like DALL-E are used for image generation.\n",
    "    How are Foundation Models used in the field of robotics?\"\"\"\n",
    "\n",
    "prompt = create_prompt(few_shot)\n",
    "\n",
    "print(send_prompt(prompt)[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ca98db-a30a-420c-bc6a-f98debc8f132",
   "metadata": {},
   "source": [
    "Chain-of-Thought Prompting: Here, you ask the AI to detail its thought process step-by-step. This is particularly useful for complex reasoning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512f005-eea3-4cae-8603-92b17d0c9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_of_thought = \"\"\"\n",
    "    Describe the process of developing a Foundation Model in AI,\n",
    "    from data collection to model training.\"\"\"\n",
    "\n",
    "prompt = create_prompt(chain_of_thought)\n",
    "\n",
    "print(send_prompt(prompt)[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192869f3-a0ee-4d12-ad4a-a5ccb66f32b2",
   "metadata": {},
   "source": [
    "Iterative Prompting: This is a process where you refine your prompt based on the outputs you get, slowly guiding the AI to the desired answer or style of answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31966f18-4146-4343-ad0c-f2597b727e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store previous messages for better context\n",
    "messages = []\n",
    "iterative = \"\"\"\n",
    "    Tell me about the latest developments in Foundation Models in AI.\"\"\"\n",
    "\n",
    "messages += create_prompt(iterative)\n",
    "\n",
    "first_response = send_prompt(messages)\n",
    "print(first_response[\"message\"][\"content\"])\n",
    "\n",
    "messages.append({\"role\": \"assistant\",\"content\":first_response[\"message\"][\"content\"]})\n",
    "\n",
    "refined = \"\"\"\n",
    "    Can you provide more details about these improvements in multi-modal learning within Foundation Models?\"\"\"\n",
    "\n",
    "messages += create_prompt(refined)\n",
    "print(\"\\n\\n----------------------------------------------------------\\n\\n\")\n",
    "print(send_prompt(messages)[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2977162e-2acc-467b-9046-210e765cd1cf",
   "metadata": {},
   "source": [
    "Negative Prompting: In this method, you tell the AI what not to do. For instance, you might specify that you don’t want a certain type of content in the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3c3dff-ec87-43e7-8d9b-3865fadfea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = \"\"\"\n",
    "    Explain the concept of Foundation Models in AI without mentioning natural language processing or NLP.\"\"\"\n",
    "\n",
    "prompt = create_prompt(one_shot)\n",
    "\n",
    "print(send_prompt(prompt)[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29db43ba-8586-4862-9d3a-38167f0c53d0",
   "metadata": {},
   "source": [
    "Hybrid Prompting: Combining different methods, like few-shot with chain-of-thought, to get more precise or creative outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3195b917-48e2-414d-beba-cb6adf29ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid = \"\"\"\n",
    "    Like GPT-3, which is a versatile model used in various language tasks, \n",
    "    explain how Foundation Models are applied in other domains of AI, such as computer vision.\"\"\"\n",
    "\n",
    "prompt = create_prompt(hybrid)\n",
    "\n",
    "print(send_prompt(prompt)[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23de2f0d-5112-4fc8-9124-7915820a58e9",
   "metadata": {},
   "source": [
    " Prompt Chaining: Breaking down a complex task into smaller prompts and then chaining the outputs together to form a final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c1d162-5b7a-475e-939d-9fb04217e5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "chaining = \"\"\"\n",
    "    List some examples of Foundation Models in AI.\"\"\"\n",
    "\n",
    "messages += create_prompt(chaining)\n",
    "\n",
    "print(send_prompt(messages)[\"message\"][\"content\"])\n",
    "\n",
    "messages.append({\"role\": \"assistant\",\"content\":first_response[\"message\"][\"content\"]})\n",
    "\n",
    "chaining_cont = \"\"\"\n",
    "    Choose one of these models and explain its foundational role in AI development.\"\"\"\n",
    "\n",
    "messages += create_prompt(chaining_cont)\n",
    "print(\"\\n\\n----------------------------------------------------------\\n\\n\")\n",
    "print(send_prompt(messages)[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f20b851-7a95-49d5-b70a-6099e65960af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
